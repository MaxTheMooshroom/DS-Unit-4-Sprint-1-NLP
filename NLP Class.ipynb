{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from IPython.display import display\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "spacy_nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NlpPipeline:\n",
    "    \n",
    "    class WrongOrderException(Exception):\n",
    "        pass\n",
    "    \n",
    "    def __init__(self, df, text_column_name, target_name, clean_name='cleaned',\n",
    "                 token_name='tokenized', nlp=spacy_nlp):\n",
    "        \"\"\"\n",
    "        A pipeline for natural language processing\n",
    "        \n",
    "        [REQUIRED]\n",
    "        df (DataFrame):\n",
    "                The dataframe with the data\n",
    "        \n",
    "        [REQUIRED]\n",
    "        text_column_name (str):\n",
    "                The name of the column of documents\n",
    "        \n",
    "        [REQUIRED]\n",
    "        target_name (str):\n",
    "                The name of the target column\n",
    "        \n",
    "        [OPTIONAL] default: \"cleaned\"\n",
    "        clean_name (str):\n",
    "                The name of the column to store cleaned values in.\n",
    "        \n",
    "        [OPTIONAL] default: \"tokenized\"\n",
    "        token_name (str):\n",
    "                The name of the column to store tokenized values in.\n",
    "                \n",
    "        [OPTIONAL] default: spacy.load(\"en_core_web_lg\")\n",
    "        nlp (spacy model):\n",
    "                A spacy language model for \n",
    "        \"\"\"\n",
    "        # Storing values\n",
    "        self.container = df\n",
    "        self.data_name = text_column_name\n",
    "        self.target_name = target_name\n",
    "        self.clean_name = clean_name\n",
    "        self.token_name = token_name\n",
    "        self.nlp = nlp\n",
    "        \n",
    "        col_names = df.columns.to_list()\n",
    "        \n",
    "        # Check if column names are already in dataframe\n",
    "        if clean_name in col_names:\n",
    "            print(\"WARNING: Value provided for parameter 'clean_name' is already a column.\")\n",
    "            \n",
    "        if token_name in col_names:\n",
    "            print(\"WARNING: Value provided for parameter 'token_name' is already a column.\")\n",
    "        \n",
    "        \n",
    "    def display(self):\n",
    "        \"\"\" A function for displaying the dataframe \"\"\"\n",
    "        display(self.container)\n",
    "        \n",
    "        \n",
    "    def Clean(self):\n",
    "        \"\"\" A function for cleaning the dataframe's \"text_col\" and storing in the \"clean_name\" column. \"\"\"\n",
    "        \n",
    "        self.container[self.clean_name] = self.container[self.data_name].apply(lambda x: BeautifulSoup(x).get_text()).apply(lambda x: re.sub(r'[^a-zA-Z ^0-9]', '', x))\n",
    "        return self.container\n",
    "    \n",
    "    \n",
    "    def Tokenize(self):\n",
    "        \"\"\" A function for tokenizing the dataframe's \"clean_col\" and storing in the \"token_name\" column. \"\"\"\n",
    "        \n",
    "        # Check that the required info exists. If not, throw exception\n",
    "        if self.clean_name not in self.container.columns.to_list():\n",
    "            raise NlpPipeline.WrongOrderException('Call .Clean() first!')\n",
    "            \n",
    "        self.container[self.token_name] = self.container[self.clean_name].apply(lambda x: [token.lemma_ for token in self.nlp(x) if (token.is_stop != True) and (token.is_punct != True)])\n",
    "        return self.container\n",
    "    \n",
    "    \n",
    "    def VectorizeCount(self):\n",
    "        \"\"\" A function for vectorizing the dataframe's \"token_name\" and storing in the \"word_count\" var. \"\"\"\n",
    "        \n",
    "        # Check that the required info exists. If not, throw exception\n",
    "        if self.token_name not in self.container.columns.to_list():\n",
    "            raise NlpPipeline.WrongOrderException('Call .Tokenize() first!')\n",
    "            \n",
    "        self.word_counts = Counter()\n",
    "        self.container[self.token_name].apply(lambda x: self.word_counts.update(x))\n",
    "        return self.word_counts\n",
    "    \n",
    "    \n",
    "    def Vectorize(self, how='tfidf'):\n",
    "        \"\"\"\n",
    "        A function for vectorizing the cleaned data and storing it as a dataframe\n",
    "        \n",
    "        [OPTIONAL] default: \"tfidf\"\n",
    "        how (str): {\"count\", \"tfidf\"}\n",
    "        \"\"\"\n",
    "        \n",
    "        if how.lower() == 'count':\n",
    "            self.vectorizer = CountVectorizer()\n",
    "            \n",
    "        elif how.lower() == 'tfidf':\n",
    "            self.vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "            \n",
    "        dtm = self.vectorizer.fit_transform(self.container[self.clean_name].to_list())\n",
    "        self.vectorized = pd.DataFrame(dtm.todense(), columns=self.vectorizer.get_feature_names())\n",
    "            \n",
    "        return self.vectorized\n",
    "    \n",
    "    \n",
    "    def MakePipeline(self, steps, verbose=False):\n",
    "        \"\"\"\n",
    "        A function for making the pipeline use in other functions\n",
    "        \n",
    "        [REQUIRED]\n",
    "        steps (list):       \n",
    "                List of (name, transform) tuples (implementing fit/transform)\n",
    "                that are chained, in the order in which they are chained, with \n",
    "                the last object an estimator.\n",
    "        \n",
    "        [OPTIONAL] default: False\n",
    "        verbose (boolean):  \n",
    "                If True, the time elapsed while fitting each step will be\n",
    "                printed as it is completed.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.pipeline = Pipeline(steps, verbose=verbose)\n",
    "        return self.pipeline\n",
    "    \n",
    "    \n",
    "    def GridSearchCV(self, parameters, cv=5, n_jobs=None, verbose=0, data_type='vectorized'):\n",
    "        \"\"\"\n",
    "        A function for creating and fitting a GridSearchCV model.\n",
    "        \n",
    "        [REQUIRED]\n",
    "        parameters (dict) or (list of dictionaries):\n",
    "                Dictionary with parameters names (string) as keys and lists\n",
    "                of parameter settings to try as values, or a list of such\n",
    "                dictionaries, in which case the grids spanned by each\n",
    "                dictionary in the list are explored. This enables searching\n",
    "                over any sequence of parameter settings.\n",
    "                \n",
    "        [OPTIONAL] default: 5\n",
    "        cv (int):\n",
    "                Determines the cross-validation splitting strategy.\n",
    "                \n",
    "        [OPTIONAL] default: None\n",
    "        n_jobs (int):\n",
    "                Number of jobs to run in parallel.\n",
    "                \n",
    "        [OPTIONAL] default: 0\n",
    "        verbose (boolean):\n",
    "                Controls the verbosity: the higher, the more messages.\n",
    "                \n",
    "        [NOT IMPLEMENTED]\n",
    "        data_type (str):\n",
    "                Will be used to select data to use for fitting\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check that the required info exists. If not, throw exception\n",
    "        if hasattr(self, 'pipeline') is False:\n",
    "            raise NlpPipeline.WrongOrderException(\"Call .MakePipeline() first!\")\n",
    "        \n",
    "        # Check that the required info exists. If not, throw exception\n",
    "        if hasattr(self, 'vectorized') is None:\n",
    "            raise NlpPipeline.WrongOrderException(\"Call .Vectorize() first!\")\n",
    "            \n",
    "        self.model = GridSearchCV(self.pipeline, parameters, cv=5, n_jobs=n_jobs, verbose=1)        \n",
    "        self.model.fit(self.vectorized, self.container[self.target_name])\n",
    "        \n",
    "        return self.model\n",
    "            \n",
    "        \n",
    "    def Predict(self, data):\n",
    "        \"\"\"\n",
    "        Function to run a pandas series through the model to predict the target\n",
    "        \n",
    "        [REQUIRED]\n",
    "        data (pandas Series):\n",
    "                the data to run through the model to predict the target\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        dtm = self.vectorizer.transform(data.to_list())\n",
    "        data = pd.DataFrame(dtm.todense(), columns=self.vectorizer.get_feature_names())\n",
    "            \n",
    "        # Check that the required info exists. If not, throw exception\n",
    "        if hasattr(self, 'model') is False:\n",
    "            raise NlpPipeline.WrongOrderException(\"Create a model first! \\nEG: my_nlp.GridSearchCV()\")\n",
    "\n",
    "        return self.model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;Create various Business Intelligence An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Everytown for Gun Safety, the nation's large...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"nfosys\\xe2\\x80\\x93 Data &amp;amp; Analytics \\xe2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0  b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "1  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...\n",
       "2  b'<div>Create various Business Intelligence An...\n",
       "3  b\"Everytown for Gun Safety, the nation's large...\n",
       "4  b\"nfosys\\xe2\\x80\\x93 Data &amp; Analytics \\xe2..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv('./module2-vector-representations/data/job_listings.csv')\n",
    "jobs = jobs[jobs['title'] == 'Data Scientist'].drop(['title', jobs.columns.to_list()[0]], axis=1).reset_index().drop(['index'], axis=1)\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nlp = NlpPipeline(jobs, 'description', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "WrongOrderException",
     "evalue": "Call .Clean() first!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWrongOrderException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fbc5dcd33c47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_nlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# testing if exception works\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-098997534b78>\u001b[0m in \u001b[0;36mTokenize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# Check that the required info exists. If not, throw exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_name\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNlpPipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWrongOrderException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Call .Clean() first!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_punct\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWrongOrderException\u001b[0m: Call .Clean() first!"
     ]
    }
   ],
   "source": [
    "my_nlp.Tokenize()  # testing if exception works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;Create various Business Intelligence An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Everytown for Gun Safety, the nation's large...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"nfosys\\xe2\\x80\\x93 Data &amp;amp; Analytics \\xe2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;FinLocker is a leading financial dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;With annual sales of $15 billion, Ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>b'&lt;div&gt;Job Description:&lt;br/&gt;\\n&lt;br/&gt;\\nThe Enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>b\"&lt;div&gt;Description:\\n&lt;p&gt;Chicago - IL, IL150SW,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>b'&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;Cerner Int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description\n",
       "0    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "1    b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...\n",
       "2    b'<div>Create various Business Intelligence An...\n",
       "3    b\"Everytown for Gun Safety, the nation's large...\n",
       "4    b\"nfosys\\xe2\\x80\\x93 Data &amp; Analytics \\xe2...\n",
       "..                                                 ...\n",
       "145  b'<div><p>FinLocker is a leading financial dat...\n",
       "146  b'<div><p>With annual sales of $15 billion, Ec...\n",
       "147  b'<div>Job Description:<br/>\\n<br/>\\nThe Enter...\n",
       "148  b\"<div>Description:\\n<p>Chicago - IL, IL150SW,...\n",
       "149  b'<div></div><div><div><div><div><p>Cerner Int...\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_nlp.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>b4969  6756 a monthContractUnder the general s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>bLocation USA xe2x80x93 multiple locationsn2 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;Create various Business Intelligence An...</td>\n",
       "      <td>bCreate various Business Intelligence Analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Everytown for Gun Safety, the nation's large...</td>\n",
       "      <td>bEverytown for Gun Safety the nations largest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"nfosys\\xe2\\x80\\x93 Data &amp;amp; Analytics \\xe2...</td>\n",
       "      <td>bnfosysxe2x80x93 Data  Analytics xe2x80x93 Sr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;FinLocker is a leading financial dat...</td>\n",
       "      <td>bFinLocker is a leading financial data and ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;With annual sales of $15 billion, Ec...</td>\n",
       "      <td>bWith annual sales of 15 billion Ecolab ECL is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>b'&lt;div&gt;Job Description:&lt;br/&gt;\\n&lt;br/&gt;\\nThe Enter...</td>\n",
       "      <td>bJob DescriptionnnThe Enterprise Data Solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>b\"&lt;div&gt;Description:\\n&lt;p&gt;Chicago - IL, IL150SW,...</td>\n",
       "      <td>bDescriptionnChicago  IL IL150SW 150 S Wacker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>b'&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;Cerner Int...</td>\n",
       "      <td>bCerner Intelligence is a new innovative organ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  \\\n",
       "0    b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "1    b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "2    b'<div>Create various Business Intelligence An...   \n",
       "3    b\"Everytown for Gun Safety, the nation's large...   \n",
       "4    b\"nfosys\\xe2\\x80\\x93 Data &amp; Analytics \\xe2...   \n",
       "..                                                 ...   \n",
       "145  b'<div><p>FinLocker is a leading financial dat...   \n",
       "146  b'<div><p>With annual sales of $15 billion, Ec...   \n",
       "147  b'<div>Job Description:<br/>\\n<br/>\\nThe Enter...   \n",
       "148  b\"<div>Description:\\n<p>Chicago - IL, IL150SW,...   \n",
       "149  b'<div></div><div><div><div><div><p>Cerner Int...   \n",
       "\n",
       "                                               cleaned  \n",
       "0    b4969  6756 a monthContractUnder the general s...  \n",
       "1    bLocation USA xe2x80x93 multiple locationsn2 y...  \n",
       "2    bCreate various Business Intelligence Analytic...  \n",
       "3    bEverytown for Gun Safety the nations largest ...  \n",
       "4    bnfosysxe2x80x93 Data  Analytics xe2x80x93 Sr ...  \n",
       "..                                                 ...  \n",
       "145  bFinLocker is a leading financial data and ana...  \n",
       "146  bWith annual sales of 15 billion Ecolab ECL is...  \n",
       "147  bJob DescriptionnnThe Enterprise Data Solution...  \n",
       "148  bDescriptionnChicago  IL IL150SW 150 S Wacker ...  \n",
       "149  bCerner Intelligence is a new innovative organ...  \n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nlp.Clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>b4969  6756 a monthContractUnder the general s...</td>\n",
       "      <td>[b4969,  , 6756, monthcontractunder, general, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>bLocation USA xe2x80x93 multiple locationsn2 y...</td>\n",
       "      <td>[bLocation, USA, xe2x80x93, multiple, location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;Create various Business Intelligence An...</td>\n",
       "      <td>bCreate various Business Intelligence Analytic...</td>\n",
       "      <td>[bcreate, Business, Intelligence, Analytical, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Everytown for Gun Safety, the nation's large...</td>\n",
       "      <td>bEverytown for Gun Safety the nations largest ...</td>\n",
       "      <td>[bEverytown, Gun, Safety, nation, large, gun, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"nfosys\\xe2\\x80\\x93 Data &amp;amp; Analytics \\xe2...</td>\n",
       "      <td>bnfosysxe2x80x93 Data  Analytics xe2x80x93 Sr ...</td>\n",
       "      <td>[bnfosysxe2x80x93, Data,  , analytic, xe2x80x9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;FinLocker is a leading financial dat...</td>\n",
       "      <td>bFinLocker is a leading financial data and ana...</td>\n",
       "      <td>[bFinLocker, lead, financial, datum, analytic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;With annual sales of $15 billion, Ec...</td>\n",
       "      <td>bWith annual sales of 15 billion Ecolab ECL is...</td>\n",
       "      <td>[bwith, annual, sale, 15, billion, Ecolab, ECL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>b'&lt;div&gt;Job Description:&lt;br/&gt;\\n&lt;br/&gt;\\nThe Enter...</td>\n",
       "      <td>bJob DescriptionnnThe Enterprise Data Solution...</td>\n",
       "      <td>[bJob, DescriptionnnThe, Enterprise, Data, Sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>b\"&lt;div&gt;Description:\\n&lt;p&gt;Chicago - IL, IL150SW,...</td>\n",
       "      <td>bDescriptionnChicago  IL IL150SW 150 S Wacker ...</td>\n",
       "      <td>[bDescriptionnChicago,  , IL, IL150SW, 150, S,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>b'&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;Cerner Int...</td>\n",
       "      <td>bCerner Intelligence is a new innovative organ...</td>\n",
       "      <td>[bCerner, Intelligence, new, innovative, organ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  \\\n",
       "0    b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "1    b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "2    b'<div>Create various Business Intelligence An...   \n",
       "3    b\"Everytown for Gun Safety, the nation's large...   \n",
       "4    b\"nfosys\\xe2\\x80\\x93 Data &amp; Analytics \\xe2...   \n",
       "..                                                 ...   \n",
       "145  b'<div><p>FinLocker is a leading financial dat...   \n",
       "146  b'<div><p>With annual sales of $15 billion, Ec...   \n",
       "147  b'<div>Job Description:<br/>\\n<br/>\\nThe Enter...   \n",
       "148  b\"<div>Description:\\n<p>Chicago - IL, IL150SW,...   \n",
       "149  b'<div></div><div><div><div><div><p>Cerner Int...   \n",
       "\n",
       "                                               cleaned  \\\n",
       "0    b4969  6756 a monthContractUnder the general s...   \n",
       "1    bLocation USA xe2x80x93 multiple locationsn2 y...   \n",
       "2    bCreate various Business Intelligence Analytic...   \n",
       "3    bEverytown for Gun Safety the nations largest ...   \n",
       "4    bnfosysxe2x80x93 Data  Analytics xe2x80x93 Sr ...   \n",
       "..                                                 ...   \n",
       "145  bFinLocker is a leading financial data and ana...   \n",
       "146  bWith annual sales of 15 billion Ecolab ECL is...   \n",
       "147  bJob DescriptionnnThe Enterprise Data Solution...   \n",
       "148  bDescriptionnChicago  IL IL150SW 150 S Wacker ...   \n",
       "149  bCerner Intelligence is a new innovative organ...   \n",
       "\n",
       "                                             tokenized  \n",
       "0    [b4969,  , 6756, monthcontractunder, general, ...  \n",
       "1    [bLocation, USA, xe2x80x93, multiple, location...  \n",
       "2    [bcreate, Business, Intelligence, Analytical, ...  \n",
       "3    [bEverytown, Gun, Safety, nation, large, gun, ...  \n",
       "4    [bnfosysxe2x80x93, Data,  , analytic, xe2x80x9...  \n",
       "..                                                 ...  \n",
       "145  [bFinLocker, lead, financial, datum, analytic,...  \n",
       "146  [bwith, annual, sale, 15, billion, Ecolab, ECL...  \n",
       "147  [bJob, DescriptionnnThe, Enterprise, Data, Sol...  \n",
       "148  [bDescriptionnChicago,  , IL, IL150SW, 150, S,...  \n",
       "149  [bCerner, Intelligence, new, innovative, organ...  \n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nlp.Tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('datum', 934),\n",
       " (' ', 469),\n",
       " ('work', 439),\n",
       " ('business', 398),\n",
       " ('experience', 353),\n",
       " ('team', 341),\n",
       " ('model', 288),\n",
       " ('data', 247),\n",
       " ('Data', 236),\n",
       " ('analysis', 213)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nlp.VectorizeCount().most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>10 apps</th>\n",
       "      <th>10 countries</th>\n",
       "      <th>10 hours</th>\n",
       "      <th>10 military</th>\n",
       "      <th>10 of</th>\n",
       "      <th>10 time</th>\n",
       "      <th>10 yearsnnthe</th>\n",
       "      <th>100</th>\n",
       "      <th>100 clean</th>\n",
       "      <th>...</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zenreach products</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zeus founders</th>\n",
       "      <th>zeus has</th>\n",
       "      <th>zeus is</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zheng the</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoom out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051814</td>\n",
       "      <td>0.051814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 41705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      10  10 apps  10 countries  10 hours  10 military  10 of  10 time  \\\n",
       "0    0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "1    0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "2    0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "3    0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "4    0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "..   ...      ...           ...       ...          ...    ...      ...   \n",
       "145  0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "146  0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "147  0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "148  0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "149  0.0      0.0           0.0       0.0          0.0    0.0      0.0   \n",
       "\n",
       "     10 yearsnnthe  100  100 clean  ...  zenreach  zenreach products  zeus  \\\n",
       "0              0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "1              0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "2              0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "3              0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "4              0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "..             ...  ...        ...  ...       ...                ...   ...   \n",
       "145            0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "146            0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "147            0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "148            0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "149            0.0  0.0        0.0  ...       0.0                0.0   0.0   \n",
       "\n",
       "     zeus founders  zeus has  zeus is     zheng  zheng the  zoom  zoom out  \n",
       "0              0.0       0.0      0.0  0.051814   0.051814   0.0       0.0  \n",
       "1              0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "2              0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "3              0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "4              0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "..             ...       ...      ...       ...        ...   ...       ...  \n",
       "145            0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "146            0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "147            0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "148            0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "149            0.0       0.0      0.0  0.000000   0.000000   0.0       0.0  \n",
       "\n",
       "[150 rows x 41705 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nlp.Vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DAY THREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.read_csv('./module3-document-classification/data/train.csv')\n",
    "kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pipeline = NlpPipeline(kaggle, 'description', 'ratingCategory')\n",
    "kaggle_pipeline.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pipeline.Clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pipeline.Tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pipeline.VectorizeCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kaggle_pipeline.Vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wc = pd.DataFrame(kaggle_pipeline.word_counts.most_common(1000), columns=['word', 'count'])\n",
    "display(wc.dtypes)\n",
    "graph = wc[wc['count'] >= 1000]\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(graph['word'], graph['count']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./module3-document-classification/data/test.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "kaggle_pipeline.MakePipeline([\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pipeline.GridSearchCV(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kaggle_pipeline.Predict(test['description'])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle_submission = pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
